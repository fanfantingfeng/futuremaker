通常，调用pandas，需要先调用numpy ：
```python
import numpy as np
import pandas as pd
```

### 基础数据结构
Pandas提供两种基础数据类型来处理数据：
1. Series : A one-dimensional labeled array holding data of any type
2. DataFrame : A two-dimensional data structure that holds data with rows and columns
[[[1.data Structures]]]

### 类型创建
##### 创建Series
通过传入 a list of values, pandas会默认创建 RangeIndex.
```python
s = pd.Series([1,3,5, np.nan,6,8])
```
##### 创建DataFrame
```python
dates = pd.date_range("20240101",periods=6)
df = pd.DateFrame(np.random.randn(6,4),index=dates,columns=list("ABCD"))
```
通过字典创建：
```python
df2 = pd.DataFrame(
		{
			"A":1.0,
			"B":pd.Timestamp("20240102"),
			"C":pd.Series(1, index=list(range(4)),dtype="float32"),
			"D":np.array([3] * 4, dtype="int32"),
			"E":pd.Categorical(["test", "train", "test","train"]),
			"F":"foo",
		}
)
df2.dtypes
#可以看到，每列的dtypes都是不同的。
```

### 查看数据
##### 查看top和bottom列的内容(默认为5）：
```python
df.head()
df.tail(3)
```
##### 查看index和columns：
```python
df.index
df.columns
```
##### 以Numpy的形式呈现数据：
```python
df.to_numpy()
```
注：由于Numpy arrays的所有序列共用一种dtype，因此调用DataFrame.to_numpy()时，pandas会用一种能够hold all of the dtypes的类型来标记Numpy array的类型。
如果DataFrame中有object类型，则调用DataFrame.to_numpy()时，会要求copying data.

##### Quick statistic summary
```python
df.describe()
```
##### 转置数据 (Transpose)
```python
df.T
```
##### 索引排序
```python
df.sort_index(axis=1,ascending=False)
```
##### 值排序
```python
df.sort_values(by="B")
```

### Selection
Python和Numpy在select方面的语句比较直观，建议在交互环境中使用；
对于脚本的编写，建议使用pandas提供的更加优雅的方法：
- DataFrame.at()
- DataFrame.iat()
- DataFrame.loc()
- DataFrame.iloc()
关于筛选数据：[[0.1基础筛选]]  [[0.2筛选进阶]]

### Gtitem(\[])
在DataFrame中，获取列信息：
```python
df["A"]
```
获取行：
```python
df[0:3]
```
通过label筛选
```python
df.loc[dates[0]]
df.loc[:, ["A", "B"]]
df.loc["20230101":"20230104", ["A", "B"]]
df.loc[dates[0], "A"]
df.at[dates[0], "A"]
```
通过位置(position)筛选
```python
df.iloc[3]
df.iloc[3:5, 0:2]
df.iloc[[1,2,4], [0,2]]
df.iloc[1:3, :]
df.iloc[:, 1:3]
df.iloc[1, 1]  #获取具体值
```

### 布尔索引
```python
df[df["A"] > 0]
df.loc[df["A"]>0, ["B","C"]]
df[df > 0]   #要求df的所有列dtype为数值
```
DataFrame.isin()生成索引：
```python
df2["E"] = ["one", "one","two","three","four","three"]
df2[df2["E"].isin(["two", "four"])]
```

### Setting(赋值)
用Series赋值DataFrame的列：
```python
s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range("20230101", periods=6))
df["F"] = s1
```
通过标签赋值：
```python
df.at[dates[0], "A"] = 0
df.iat[0, 1] = 0   #都通过默认index来索引
df.loc[:, "D"] = np.array([5] * len(df))
```
A **where** operation with setting:
```python
df2 = df.copy()
df2[df2 > 0] = -df2
```

### 缺失值
在NumPy类型中， np.nan代表缺失值。
Reindexing 让我们能change/add/delete 指定axis的索引。
```python
df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ["E"])
df1.loc[dates[0]:dates[1], "E"] = 1
```
DataFrame.dropna() 删除缺失值：
```python
df1.dropna(how="any")  #删除存在缺失值的任意行
```
DataFrame.fillna()替换缺失值：
```python
df1.fillna(value=5)   #将缺失值替换为5
```
pd.isna() 获取 boolean mask判断是否值为 nan：
```python
pd.isna(df1)
```

### Operations (基础运算)
##### Stats (描述性统计)
```python
df.mean()  #求axis=0唯独的平均值
df.mean(axis=1)
```
pandas 默认沿着指定的纬度(axis)进行广播运算，对于未对齐(unaligned)的标签用 np.nan 来替换。
```python
s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)
df.sub(s, axis="index")   #用df的每一列来加s
```

##### 自定义函数
DataFrame.agg()和 DataFrame.transform()接受用户自定义函数来累计(reduce)或广播(broadcast)其结果。
```python
df.agg(lambda x:np.mean(x) * 5.6)
df.transform(lambda x:x * 101.2)
```

##### 计数(value counts)
```python
s = pd.Series(np.random.randint(0, 7, size=10))
s.value_counts()
```

##### 字符串处理
Series 有一个 .str方法来处理字符串。  [[0.3字符串方法]]
```python
s.str.lower()
```


### 合并(Merge)
##### Concat
Row-wise concatenating pandas objects together:
```python
df = pd.DataFrame(np.random.randn(10,4))
pieces = [df[:3], df[3:7], df[7:]]
pd.concat(pieces)
```
对DataFrame而言，添加一个column是很快的，但如果添加row的话，需要进行copy操作，非常占用内存。
**We recommand passing a pre-built list of records to the DataFrame constructor instead of building a DataFrame by iteratively appending records to it.**

##### Join
pd.merge() 支持SQL风格的合并方式。
```python
left = pd.DataFrame({"key":["foo","foo"], "lval":[1,2]})
right = pd.DataFrame({"key":["foo","foo"], "rval":[4,5]})
pd.merge(left, right, on="key")
```
由于"key"列存在重复的值做索引， 因此合并结果会产生笛卡尔积。


### Grouping
通过 group by 技术，实际上执行的是以下步骤：
- Spliting the data into groups based on some criteria
- Applying a function to each group independency
- Combining the results into a data structure
[[0.4Grouping]]
```python
df = pd.DataFrame(
	{
		"A":["foo", "bar", "foo", "bar","foo","bar", "foo", "foo"],
		"B":["one","one","two","three","two","two","one","three"],
		"C":np.random.randn(8),
		"D":np.random.randn(8),
	}
)
df.groupby("A")[["C", "D"]].sum()
df.groupby(["A","B"]).sum()
```

### Reshaping
[[0.5Reshaping]]
##### Stack
```python
arrays = [
	["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
	["one", "two", "one", "two", "one", "two", "one", "two"],
]
index = pd.MultiIndex.from_arrays(arrays, names=["first", "second"])
df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=["A", "B"])
df2 = df[:4]
```
The *stack()* method "compresses" a level in the DataFrame's columns:
```python
stacked = df2.stack(future_stack=True) #效果类似逆透视
```
"stacked" DataFrame或Series的index一般为MultiIndex，stack()的逆操作为 unstack()，默认情况下， unstack the last level:
```python
stacked.unstack()
stacked.unstack(1)
stacked.unstack(2)
```
##### Pivot tables
[[0.6Pivot]]
```python
df = pd.DataFrame(
	{
		"A":["one","one","two","three"] * 3,
		"B":["A","B","C"] *4,
		"C":["foo","foo","foo","bar","bar","bar"] * 2,
		"D":np.random.randn(12),
		"E":np.random.randn(12),
	}
)
pd.pivot_table(df, values="D", index=["A", "B"], columns=["C"])
```

### Time Series
[[0.7Time Series]]
```python
rng = pd.date_range("1/1/2024", periods=100, freq="s")
ts = pd.Series(np.random.randint(0,500, len(rng)), index=rng)
ts.resample("5Min").sum()
```
Series.tz_localize() 用于将时间序列匹配到时区：
```python
ts_utc = ts.tz_localize("UTC")
```
Series.tz_convert() 将含时区的时间序列转换到指定时区：
```python
ts_utc.tz_convert("US/Eastern")
```
添加 BusinessDay(工作日) 到时间序列:
```python
rng + pd.offsets.BusinessDay(5)
```

### Categoricals
[[0.8Categorical]]
```python
df = pd.DataFrame(
	{
		"id":[1,2,3,4,5,6],
		"raw_grade":["a","b","b","a","a","e"],
	}
)
```
将 raw grade转换为 categorical data type:
```python
df["grade"] = df["raw_grade"].astype("category")
new_categories = ["verey goo", "good", "very bad"]
df["grade"] = df["grade"].cat.rename_categories(new_categories)
```
Series.cat()方法默认会返回一个新的 Series。
```python
df["grade"] = df["grade"].cat.set_categories(
	["very bad", "bad", "medium", "good", "very good"]							 
)
df.sort_values(by="grade")
```
Grouping by a categorical column with *observed=False* aslo shows empty categories:
```python
df.groupby("grade", observed=False).size()
```

### Plotting
[[0.9Plotting]]
pandas作图一般调用 matplotlib API：
```python
import matplotlib.pyplot as plt
plt.close("all")  #关闭 figure window
ts = pd.Series(np.random.randn(1000), index=pd.date_range("1/1/2024",periods=1000))
ts = ts.cumsum()
ts.plot()
```
注：如果使用Jupyter，画布在使用plot()后自动出现； 否则需要调用 matplotlib.pyplot.show来呈现，或调用matplotlib.pyplot.savefig来保存图片。
如果需要画出所有column：
```python
df = df.cumsum()
plt.figure()
df.plot()
plt.legend(loc="best")
```

### Importing and exporting data
[[0.10IO Tools]]
##### CSV
```python
df = pd.read_csv("foo.csv")
df.to_cvs("foo.csv")
```
##### Parquet
```python
df = pd.read_parquet("foo.parquet")
df.to_parquet("foo.parquet")
```
##### Excel
```python
df = pd.read_excel("foo.xlsx", "Sheet1", index=None, na_values=["NA"])
df.to_excel("foo.xlsx", sheet_name="Sheet1")
```


Next [[1.data Structures]]
